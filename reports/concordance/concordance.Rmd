---
author: "Centre for Population Genomics"
date: "`r Sys.time()`"
output:
  html_document:
    theme: simplex
    toc: true
    code_download: true
    code_folding: show
  rmdformats::material:
    highlight: kate
params:
  TITLE: "TOB-WGS concordance of SNPchip and WGS genotype calls"
  SNP_MT: ""
  WGS_MT: ""
  RES_SAMPLES: ""
  RES_SITES: ""
  CPU: ""
title: "`r paste(params$TITLE)`"
---

```{r knitr_opts, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = TRUE, message = TRUE)
```

## Introduction

Here we're exploring genotype concordance between SNPchip and WGS data for the
TOB-WGS project. We have been provided with one multi-sample VCF file containing
genotype calls from the SNPchip data (`onek1k_pre_imputation_genotypes.vcf.gz`),
and several single-sample GVCF files containing genotype calls from the WGS data
(merged into a Hail [MatrixTable](https://hail.is/docs/0.2/hail.MatrixTable.html) (MT)
for processing).

The main steps for calculating concordance between the SNPchip and WGS data
are:

1. Rename the samples in the SNPchip VCF based on the
   `OneK1K_sample_IDs_2021-Apr-15.xlsx` map of SNPchip IDs to TOB IDs
   (provided in 2021-Apr-15).
2. Convert the SNPchip VCF from the GRCh37 human genome assembly to GRCh38
   using [Hail liftover] so that it's the same assembly as the WGS MT.
3. Process the WGS sparse MT using:
   - [Hail densify] which converts a sparse MT to a dense VCF-like
     representation by expanding reference blocks. The `END` entry field of the MT
     is dropped.
   - [Hail lgt_to_gt] to transform LGT (local GT) into GT using local alleles array.
   - [Hail split_multi_hts] to keep biallelic and multiallelic variants
     (i.e. remove monoallelic variants);
4. Use [Hail concordance] to calculate the concordance between the
   SNPchip and WGS calls.

[Hail liftover]: https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover
[Hail split_multi_hts]: https://hail.is/docs/0.2/methods/genetics.html#hail.methods.split_multi_hts
[Hail densify]: https://hail.is/docs/0.2/experimental/vcf_combiner.html#hail.experimental.densify
[Hail lgt_to_gt]: https://hail.is/docs/0.2/experimental/vcf_combiner.html#hail.experimental.lgt_to_gt
[Hail concordance]: https://hail.is/docs/0.2/methods/genetics.html#hail.methods.concordance

- Load required R packages:

```{r load_pkgs}
library(dplyr, include.only = c("%>%", "select", "mutate", "tibble", "bind_rows"))
library(DT, include.only = c("datatable", "formatCurrency", "formatStyle", "styleColorBar"))
library(glue, include.only = "glue")
library(htmltools, include.only = c("tags", "div"))
library(jsonlite, include.only = "fromJSON")
library(purrr, include.only = c("map", "set_names"))
library(readr, include.only = c("write_tsv", "read_tsv", "cols"))
library(readxl, include.only = "read_excel")
library(reticulate, include.only = c("use_condaenv", "py"))
library(rlang, include.only = c("is_integer", "is_double"))
library(tidyr, include.only = "unnest")
library(tidyselect, include.only = "vars_select_helpers")
use_condaenv("hailr", required = TRUE)
```

```{r read_params, eval=FALSE, echo=FALSE}
# for interactive debugging
params <- rmarkdown::yaml_front_matter("concordance.Rmd")$params
```

```{python hail_setup}
import hail as hl
hl.init(default_reference='GRCh38', master=f'local[{r.params["CPU"]}]')
```

## Step 1: Rename VCF samples

(Pre-executed once)

```{r generate_id_map, eval=FALSE}
chipid2tobid_tsv <- "chipid2tobid.tsv"

"OneK1K_sample_IDs_2021-Apr-15.xlsx" %>%
  read_excel(skip = 1) %>%
  mutate(tob_id = glue("TOB{TOB_ID}")) %>%
  select(sample = PERSON, tob_id) %>%
  write_tsv(file = chipid2tobid_tsv, col_names = FALSE)
```

```{r bcftools_reheader, eval=FALSE}
vcf_reheader <- "snpchip_rehead_grch37.vcf.gz"
system(glue("bcftools reheader ",
            "-s {chipid2tobid_tsv} ",
            "-o {vcf_reheader} ",
            "onek1k_pre_imputation_genotypes.vcf.gz"))
```

## Step 2: Liftover from GRCh37 to GRCh38

(Pre-executed once)

```{python hail_liftover, eval=FALSE}
def liftover(x, chain):
    """
    Liftover matrix table x from GRCh37 to GRCh38
    """
    rg37 = hl.get_reference('GRCh37')
    rg38 = hl.get_reference('GRCh38')
    rg37.add_liftover(chain, rg38)
    x = x.annotate_rows(new_locus=hl.liftover(x.locus, 'GRCh38'))
    x = x.filter_rows(hl.is_defined(x.new_locus))
    x = x.key_rows_by(locus=x.new_locus)
    return x

# Liftover to GRCh38 and write
mt = hl.import_vcf(r.vcf_reheader, reference_genome='GRCh37', force_bgz=True)
mt = liftover(mt, 'grch37_to_grch38.over.chain.gz')
mt.write('snpchip_rehead_grch38.mt', overwrite=True)
```

## Step 3: WGS MatrixTable pre-processing

```{python hail_densify_split_multi}
wgs = hl.read_matrix_table(r.params['WGS_MT'])
snp = hl.read_matrix_table(r.params['SNP_MT']).key_rows_by('locus', 'alleles')

#---- select TOB1524 + chr22 ----#
wgs = wgs.filter_cols(wgs.s == 'TOB1524')
snp = snp.filter_cols(snp.s == 'TOB1524')
wgs = wgs.filter_rows(wgs.locus.contig == 'chr22')
snp = snp.filter_rows(snp.locus.contig == 'chr22')

#---- densify and lgt_to_gt ----#
wgs = hl.experimental.densify(wgs)
wgs = wgs.annotate_entries(GT=hl.experimental.lgt_to_gt(wgs.LGT, wgs.LA))

#---- split multiallelic and keep biallelic rows ----#
wgs = hl.split_multi_hts(wgs)
wgs = wgs.filter_rows(hl.len(wgs.alleles) == 2)

#---- unphase genotypes ----#
wgs = wgs.annotate_entries(
    GT=hl.case()
    .when(wgs.GT.is_diploid(), hl.call(wgs.GT[0], wgs.GT[1], phased=False))
    .when(wgs.GT.is_haploid(), hl.call(wgs.GT[0], phased=False))
    .default(hl.missing(hl.tcall))
)

bout = 'gs://cpg-tob-wgs-test/concordance/v1/outputs/densified'
wgs.write(f'{bout}/wgs_tob1524_chr22.mt', overwrite=True)
snp.write(f'{bout}/snp_tob1524_chr22.mt', overwrite=True)
```

## Step 4: Concordance calculation

```{python hail_concordance}
global_conc, cols_conc, rows_conc = hl.concordance(snp, wgs)

# write concordance stats per sample
cols_conc.export(r.params["RES_SAMPLES"], delimiter='\t')

# write concordance stats per site
rows_conc.export(r.params["RES_SITES"], delimiter='\t')
```

## Results

```{r concordance_results}
get_mat_stats <- function(m) {
  mat_rename <- function(m) {
    conc_names <- c("missing_variant", "missing_gt", "homref", "het", "homalt")
    colnames(m) <- glue("{conc_names}_right")
    rownames(m) <- glue("{conc_names}_left")
    m
  }
  mat_conc_stats <- function(m) {
    conc_tot1 <- sum(
      m["homref_left", "homref_right"],
      m["het_left", "het_right"],
      m["homalt_left", "homalt_right"])
    conc_tot2 <- m["homref_left", "missing_variant_right"] # these are mostly in homref WGS blocks
    conc_tot <- conc_tot1 + conc_tot2
    disc_tot1 <- sum(m[3:5, 3:5]) - conc_tot1
    disc_tot2 <- m["het_left", "missing_variant_right"] + m["homalt_left", "missing_variant_right"]
    disc_tot <- disc_tot1 + disc_tot2

    # missing, homrefs, hets and homalts
    left_tot <- sum(m[c(2, 3, 4, 5), ])
    right_tot <- sum(m[, c(2, 3, 4, 5)])
    conc_over_left <- conc_tot / left_tot
    conc_over_right <- conc_tot / right_tot
    disc_over_left <- disc_tot / left_tot
    disc_over_right <- disc_tot / right_tot
    tibble(disc_tot = disc_tot,
           conc_tot = conc_tot,
           right_tot = right_tot,
           left_tot = left_tot,
           `conc / right` = conc_over_right,
           `conc / left` = conc_over_left,
           `disc / left` = disc_over_left,
           `disc / right` = disc_over_right)
  }
  m %>% mat_rename() %>% mat_conc_stats()
}

res <- params$RES_SAMPLES %>%
  read_tsv(col_types = "ccd") %>%
  mutate(conc2 = map(concordance, ~fromJSON(.) %>% get_mat_stats)) %>%
  unnest(conc2) %>%
  select(sample = s, `conc / left`, `conc / right`,
         conc_tot, disc_tot,
         left_tot, right_tot,
         `disc / left`, `disc / right`)

cap <- tags$caption(
  div("Concordance statistics per sample."),
  div("conc: concordant; disc: discordant;"),
  div("left/right: left and right datasets used in hail.concordance(left, right)."),
  div("left: SNP dataset; right: WGS dataset."))
res %>%
  mutate(across(where(is.numeric), ~round(.x, 4))) %>%
  datatable(rownames = FALSE,
            caption = cap,
            class = "cell-border display compact",
            filter = list(position = "top", clear = FALSE, plain = TRUE),
            extensions = c("Scroller", "KeyTable", "Buttons"),
            options = list(scroller = TRUE, scrollX = TRUE, scrollY = 700,
                           buttons = 'csv', keys = TRUE, dom = "Blfrtip")) %>%
  formatStyle(res %>% select(where(is_double)) %>% names(),
              background = styleColorBar(c(0, 1), "lightgreen"),
              backgroundSize = "90% 90%",
              backgroundRepeat = "no-repeat", backgroundPosition = "center") %>%
  formatCurrency(res %>% select(where(is_integer)) %>% names(),
                 currency = "", interval = 3, mark = ",", digits = 0)
```
