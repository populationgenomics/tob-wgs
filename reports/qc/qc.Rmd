---
author: "Centre for Population Genomics"
date: "`r as.character(paste(Sys.time(), Sys.timezone()))`"
output:
  html_document:
    theme: cosmo
    toc: true
    code_download: true
    code_folding: hide
  rmdformats::material:
    highlight: kate
params:
  title: ""
  gvcf_bucket_suffix: "test"
  gender_tsv: "work/test/gender.tsv"
  age_csv: "work/test/age.csv"
  meta_tsv: "work/test/meta.tsv"
  qc_csv: "work/test/qc.csv"
  test: TRUE
title: "QC report for TOB-WGS"
---

```{r knitr_opts, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Introduction

Here we're exploring QC metrics, metadata, and contents of Google Cloud Storage
buckets associated with the TOB-WGS project.

```{r load_pkgs}
library(tidyverse)
library(fs)
library(glue)
library(assertthat)
library(reactable)
library(ggrepel)
library(sessioninfo)
library(DT)
library(ggforce)

# for GCS authentication
library(googleCloudStorageR)
library(gargle)
```

```{r read_params, eval=FALSE, echo=FALSE}
# for interactive debugging
params <- rmarkdown::yaml_front_matter("qc.Rmd")$params
```

```{r funcs}
guess_file_type <- function(x) {
  dplyr::case_when(
    grepl("\\.bam$", x, ignore.case = TRUE) ~ "BAM",
    grepl("\\.bai$", x, ignore.case = TRUE) ~ "BAMindex",
    grepl("\\.cram$", x, ignore.case = TRUE) ~ "CRAM",
    grepl("\\.crai$", x, ignore.case = TRUE) ~ "CRAMindex",
    grepl("\\.fastq.gz$", x, ignore.case = TRUE) ~ "FASTQ",
    grepl("\\.fastq$", x, ignore.case = TRUE) ~ "FASTQ",
    grepl("\\.fq$", x, ignore.case = TRUE) ~ "FASTQ",
    grepl("\\.fq\\.gz$", x, ignore.case = TRUE) ~ "FASTQ",
    grepl("manifest\\.txt$", x, ignore.case = TRUE) ~ "Manifest",
    grepl("\\.md5$", x, ignore.case = TRUE) ~ "MD5",
    grepl("md5\\.txt$", x, ignore.case = TRUE) ~ "MD5txt",
    grepl("\\.vcf$", x, ignore.case = TRUE) ~ "VCF_unz",
    grepl("\\.g\\.vcf\\.gz$", x, ignore.case = TRUE) ~ "GVCF",
    grepl("\\.vcf\\.gz$", x, ignore.case = TRUE) ~ "VCF",
    grepl("\\.tbi$", x, ignore.case = TRUE) ~ "VCFindex",
    grepl("\\.csv$", x, ignore.case = TRUE) ~ "CSV",
    grepl("\\.json$", x, ignore.case = TRUE) ~ "JSON",
    TRUE ~ "OTHER")
}

gcs_list_objects2 <- function(b, prefix) {
  googleCloudStorageR::gcs_list_objects(
    bucket = b,
    prefix = prefix,
    detail = "summary"
  ) %>%
  as_tibble() %>%
  mutate(
    name = glue("gs://{b}/{name}"),
    size = sub(" bytes", "", size), # else returns NA
    size = fs::as_fs_bytes(size),
    ftype = guess_file_type(name)
  )
}

# The given observation x is considered an outlier
# (see https://statsandr.com/blog/outliers-detection-in-r/).
# Using the m parameter for cases where there are simply too many outliers; the
# larger the value of m, the fewer values are considered outliers.
is_outlier <- function(x, m = 1.5) {
  assert_that(is.numeric(x), is.numeric(m))
  (x < quantile(x, 0.25) - m * IQR(x)) |
    (x > quantile(x, 0.75) + m * IQR(x))
}
```

```{r vars}
bucket <- glue("cpg-tob-wgs-", params$gvcf_bucket_suffix)
gcs_prefix <- "gvcf"
```

## WGS GVCF files

- Let's first explore the contents of `r glue("'{bucket}/{gcs_prefix}'")`:

```{r list_contents1}
scope <- c("https://www.googleapis.com/auth/cloud-platform")
token <- gargle::token_fetch(scopes = scope)
googleCloudStorageR::gcs_auth(token = token)
obj_list <- gcs_list_objects2(b = bucket, prefix = gcs_prefix)
```

```{r list_contents2}
count(obj_list, ftype) %>% knitr::kable(caption = glue("Count of file types in '{bucket}/{gcs_prefix}'."))
gvcf <-
  obj_list %>%
  filter(ftype == "GVCF") %>%
  mutate(basename = basename(name),
         tobid = sub(".g.vcf.gz", "", basename),
         batch = sub("batch(.)", "\\1", basename(dirname(name)))) %>%
  select(tobid, fullname = name, batch, size, basename)
```

- Total of **`r nrow(obj_list)`** files, consisting of **`r nrow(gvcf)`**
  GVCF files:

```{r gvcf_list}
gvcf %>%
  mutate(size = as.character(size),
         n = dplyr::row_number()) %>%
  select(n, fullname, batch, size) %>%
  reactable::reactable(
    pagination = FALSE, highlight = TRUE, height = 500, searchable = TRUE,
    filterable = TRUE, bordered = TRUE, fullWidth = FALSE,
    columns = list(
      n = colDef(minWidth = 60),
      fullname = colDef(minWidth = 420),
      batch = colDef(minWidth = 60),
      size = colDef(minWidth = 80)
    )
  ) %>%
  htmlwidgets::prependContent(
    htmltools::h2(
      class = "title",
      glue("GVCF files in '{bucket}/{gcs_prefix}' (Total: {nrow(gvcf)})")))
```

```{r gvcf_file_sizes}
theme_set(theme_bw())

gvcf %>%
  summarise(
    min = as_fs_bytes(min(size)),
    max = as_fs_bytes(max(size)),
    q1 = as_fs_bytes(quantile(size, 0.25)),
    median = as_fs_bytes(median(size)),
    q3 = as_fs_bytes(quantile(size, 0.75)),
    total = as_fs_bytes(sum(size)),
    .groups = "drop") %>%
  tidyr::pivot_longer(cols = dplyr::everything()) %>%
  knitr::kable(caption = glue("Size metrics for {nrow(gvcf)} GVCF files in '{bucket}/{gcs_prefix}'."))

gvcf %>%
  mutate(
    size_clean = stringr::str_trim(size),
    outlier = dplyr::if_else(
      is_outlier(size, 3),
      glue("{tobid} ({size_clean})"),
      NA_character_
    )
  ) %>%
  ggplot(aes(x = batch, y = size)) +
  geom_violin(fill="lightblue") +
  ggforce::geom_sina(shape = 21, color = "darkblue", fill = "red", seed = 42) +
  ggrepel::geom_text_repel(aes(label = outlier),
                           na.rm = TRUE, hjust = -0.6, seed = 42) +
  scale_y_continuous(labels = scales::comma, breaks = scales::breaks_pretty(10)) +
  theme(panel.grid.minor = element_blank()) +
  ggtitle(glue("Size (bytes) for {nrow(gvcf)} GVCF files in '{bucket}/{gcs_prefix}'."))
```

## QC metrics

We have access to CSV files with summaries of sample QC metrics. Additional
files have been provided containing the recorded age and sex of each sample.

```{r qc_plot_prep}
sample_qc_meta <- params$meta_tsv %>%
  read_tsv() %>%
  select(
    sample = s,
    singleton = sample_qc.n_singleton,
    snp = sample_qc.n_snp,
    ti_tv = sample_qc.r_ti_tv,
    het_hom = sample_qc.r_het_hom_var,
    indel_ratio = sample_qc.r_insertion_deletion,
    sample_filters = sample_filters,
    high_quality = high_quality,
    `chr20 mean dp` = chr20_mean_dp,
    is_female,
    sex_karyotype
  )

qc_kccg <- params$qc_csv %>%
  read_csv() %>%
  select(
    sample = sample.sample_name,
    contamination = raw_data.FREEMIX,
    chimeras = raw_data.PCT_CHIMERAS,
    duplicates = raw_data.PERCENT_DUPLICATION,
    `insert size median` = raw_data.MEDIAN_INSERT_SIZE
  )

gender <- params$gender_tsv %>%
  read_tsv(
    skip = 2,
    col_names = c(
      "sample_id",
      "sample.sample_name",
      "gender",
      paste0("nanodrop_", c("conc", "260/280", "230/280")),
      paste0("qubit_", c("assay_conc", "stock_conc")),
      "volume",
      "location"
    )
  ) %>%
  filter(!is.na(sample_id)) %>%
  select(sample = sample.sample_name, gender)

age <- params$age_csv %>%
  read_csv(col_types = cols(.default = "c", age = "d")) %>%
  select(sample = TOBIID, age)

all_data <- qc_kccg %>%
  left_join(sample_qc_meta, by = "sample") %>%
  left_join(gender, by = "sample") %>%
  left_join(age, by = "sample") %>%
  left_join(gvcf %>% select(sample = tobid, batch), by = "sample")

p_data <- all_data %>%
  tidyr::pivot_longer(
    cols = c("contamination", "chimeras", "duplicates", "insert size median",
             "singleton", "snp", "ti_tv", "het_hom", "indel_ratio",
             "chr20 mean dp"),
    names_to = "metric") %>%
  group_by(metric) %>%
  mutate(
    `Bad quality` = !high_quality,
    value_round = round(value, 3),
    label = if_else(is_outlier(value) | !high_quality, glue("{sample} ({value_round})"), NA_character_)
  )

cutoffs <- tibble(
  metric   =  c("singleton", "snp",    "het_hom", "chimeras", "chr20 mean dp", "duplicates", "contamination", "insert size median"),
  upper_lim = c(100000,       8000000,  3.3,       0.05,       NA,              0.3,          0.05,            NA),
  lower_lim = c(NA,           2400000,  NA,        NA,         15,              NA,           NA,              250)
)

cutoffs <- cutoffs %>% filter(metric %in% unique(p_data$metric))
```

```{r}
n_metrics <- length(unique(p_data$metric))
plot_width <- n_metrics * 1.2
plot_height <- n_metrics * 1
```

Here we plot distributions of several metrics:

```{r fig.width=plot_width, fig.height=plot_height}
p_data %>%
  ggplot(aes(x = "", y = value, label = label)) +
  geom_violin(fill = "transparent") +
  geom_sina(aes(colour = high_quality, shape = batch, group = metric), seed = 42) +
  geom_text_repel(color = "black", na.rm = TRUE, size = 2.3) +
  geom_hline(data = cutoffs, aes(yintercept = upper_lim), color = "red") +
  geom_hline(data = cutoffs, aes(yintercept = lower_lim), color = "blue") +
  facet_wrap(~metric, scales = "free", nrow = 2) +
  scale_y_continuous(breaks = scales::breaks_pretty(8)) +
  theme(axis.ticks.x = element_blank(), axis.text.x = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  ggtitle(glue("QC metrics (for {length(unique(p_data$sample))} samples).")) +
  xlab("")
```

Same, grouped by batch:

```{r}
if (params$test && length(unique(p_data$batch)) == 1) {
  # adding fake batches for debug purposes
  p_data = p_data %>% bind_rows(p_data %>% mutate(batch = "2"), p_data %>% mutate(batch = "3"), p_data %>% mutate(batch = "4"))
}

n_batches <- length(unique(p_data$batch))
n_metrics <- length(unique(p_data$metric))
plot_width <- n_batches * 3
plot_height <- n_metrics * 3
```

```{r fig.width=plot_width, fig.height=plot_height}
p_data %>%
  ggplot(aes(x = "", y = value, label = label)) +
  geom_violin(fill = "transparent") +
  geom_sina(aes(colour = high_quality, group = metric), seed = 42) +
  ggrepel::geom_text_repel(
    color = "black", na.rm = TRUE, size = 2.3
  ) +
  geom_hline(data = cutoffs, aes(yintercept = upper_lim), color="red") +
  geom_hline(data = cutoffs, aes(yintercept = lower_lim), color="blue") +
  facet_grid(metric~batch, scales = "free") +
  scale_y_continuous(breaks = scales::breaks_pretty(8)) +
  theme(
    axis.ticks.x = element_blank(),
    axis.text.x = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  ) +
  ggtitle(glue("QC metrics by batch (for {length(unique(p_data$sample))} samples).")) +
  xlab("")
```

```{r}
# Render a bar chart in the background of the cell
bar_style <- function(width = 1, fill = "#e6e6e6", height = "75%", align = c("left", "right"), color = NULL) {
  align <- match.arg(align)
  if (align == "left") {
    position <- paste0(width * 100, "%")
    image <- sprintf("linear-gradient(90deg, %1$s %2$s, transparent %2$s)", fill, position)
  } else {
    position <- paste0(100 - width * 100, "%")
    image <- sprintf("linear-gradient(90deg, transparent %1$s, %2$s %1$s)", position, fill)
  }
  list(
    backgroundImage = image,
    backgroundSize = paste("100%", height),
    backgroundRepeat = "no-repeat",
    backgroundPosition = "center",
    color = color
  )
}

data = all_data %>%
  transmute(
    n = dplyr::row_number(),
    sample, 
    batch,
    `sex inferred/reported` = str_c(sex_karyotype, "/", gender),
    `chr20 mean DP` = `chr20 mean dp`, 
    contamination = contamination,
    `filters` = str_replace(sample_filters, "\\[\\]", "") %>% str_replace("\\[\"", "") %>% str_replace("\"\\]", ""),
    `high quality` = high_quality,
    age,
    `indel ratio` = indel_ratio, 
    `het/hom` = het_hom,
    `ti/tv` = ti_tv,
    snp = snp,
    singleton = singleton,
    `insert size median` = `insert size median`,
    duplicates = duplicates,
    chimeras = chimeras
  )

data %>%
  reactable::reactable(
    pagination = FALSE, highlight = TRUE, height = 500, searchable = TRUE,
    filterable = TRUE, bordered = TRUE, fullWidth = FALSE,
    columns = list(
      n = colDef(),
      batch = colDef(),
      sample = colDef(),
      `sex inferred/reported` = colDef(style = function(value) { list(background = ifelse(value != "XX/F" & value != "XY/M", 'red', 'white')) }),
      `chr20 mean DP` = colDef(
        style = function(value) {
          bar_style(width = value / max(data$`chr20 mean DP`), fill = "hsl(208, 70%, 90%)")
        },
        format = colFormat(digits = 1, suffix = "x")
      ),
      contamination = colDef(
        style = function(value) {
          bar_style(width = value / max(data$contamination), fill = "hsl(208, 70%, 90%)")
        },
        format = colFormat(digits = 2, percent = TRUE)
      ),
      filters = colDef(),
      `high quality` = colDef(style = function(value) { list(background = ifelse(value, 'white', 'red')) }),
      age = colDef(
        style = function(value) {
          bar_style(width = value / max(data$age), fill = "hsl(208, 70%, 90%)")
        }
      ),
      `indel ratio` = colDef(
        style = function(value) {
          bar_style(width = value / max(data$`indel ratio`), fill = "hsl(208, 70%, 90%)")
        },
        format = colFormat(digits = 2)
      ),
      `het/hom` = colDef(
        style = function(value) {
          bar_style(width = value / max(data$`het/hom`), fill = "hsl(208, 70%, 90%)")
        },
        format = colFormat(digits = 2)
      ),
      `ti/tv` = colDef(
        style = function(value) {
          bar_style(width = value / max(data$`het/hom`), fill = "hsl(208, 70%, 90%)")
        },
        format = colFormat(digits = 2)
      ),
      snp = colDef(
        style = function(value) {
          bar_style(width = value / max(data$snp), fill = "hsl(208, 70%, 90%)")
        }
      ),
      singleton = colDef(
        style = function(value) {
          bar_style(width = value / max(data$singleton), fill = "hsl(208, 70%, 90%)")
        }
      ),
      `insert size median` = colDef(
        style = function(value) {
          bar_style(width = value / max(data$`insert size median`), fill = "hsl(208, 70%, 90%)")
        }
      ),
      duplicates = colDef(
        style = function(value) {
          bar_style(width = value / max(data$duplicates), fill = "hsl(208, 70%, 90%)")
        },
        format = colFormat(digits = 2, percent = TRUE)
      ),
      chimeras = colDef(
        style = function(value) {
          bar_style(width = value / max(data$chimeras), fill = "hsl(208, 70%, 90%)")
        },
        format = colFormat(digits = 2, percent = TRUE)
      )
    )
  ) %>%
  htmlwidgets::prependContent(
    htmltools::h2(
      class = "title",
      glue("{nrow(all_data)} samples in {n_batches} batches")
    )
  )
```

Exploring the bimodal duplication rate distribution across batches.

```{r}
all_data %>% count(batch,  duplicates > 0.15, duplicates < 0.15,  duplicates > 0.12, duplicates > 0.12)
```

```{r}
all_data %>% filter(batch == "1", duplicates > 0.12) %>% dplyr::pull(sample)
```

```{r}
all_data %>% filter(batch == "1", duplicates <= 0.12) %>% dplyr::pull(sample)
```


```{r}
all_data %>% filter(batch == "3", duplicates > 0.15) %>% dplyr::pull(sample)
```
```{r}
all_data %>% filter(batch == "3", duplicates <= 0.15) %>% dplyr::pull(sample)
```


## Session Info

```{r session_info, echo=FALSE}
si <- sessioninfo::session_info(include_base = TRUE)
si_pl <- unclass(si$platform) %>% as_tibble() %>% t()
si_pkg <- unclass(si$packages) %>%
  as_tibble() %>%
  select(package, version = ondiskversion, datestamp = date)
tibble(var = rownames(si_pl),
              value = si_pl[, , drop = TRUE]) %>%
  knitr::kable(caption = "Platform information.")
si_pkg %>%
  DT::datatable(filter = list(position = "top", clear = FALSE, plain = TRUE),
                rownames = FALSE, extensions = c("Scroller"),
                options = list(scroller = TRUE, scrollX = TRUE, scrollY = 200,
                               dom = 'Bfrtip'))
```
