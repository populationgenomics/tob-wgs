---
author: "Centre for Population Genomics"
date: "`r as.character(paste(Sys.time(), Sys.timezone()))`"
output:
  html_document:
    theme: cosmo
    toc: true
    code_download: true
    code_folding: show
  rmdformats::material:
    highlight: kate
params:
  title: ""
  gvcf_bucket_suffix: "test"
  gender_tsv: "work/test/gender.tsv"
  age_csv: "work/test/age.csv"
  meta_tsv: "work/test/meta.tsv"
  qc_csv: "work/test/qc.csv"
title: "QC report for TOB-WGS"
---

```{r knitr_opts, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Introduction

Here we're exploring QC metrics, metadata, and contents of Google Cloud Storage
buckets associated with the TOB-WGS project.

```{r load_pkgs}
library(tidyverse)
library(fs)
library(glue)
library(assertthat)
library(reactable)
library(ggrepel)
library(sessioninfo)
library(DT)
library(ggforce)

# for GCS authentication
library(googleCloudStorageR)
library(gargle)
```

```{r read_params, eval=FALSE, echo=FALSE}
# for interactive debugging
params <- rmarkdown::yaml_front_matter("qc.Rmd")$params
```

```{r funcs}
guess_file_type <- function(x) {
  dplyr::case_when(
    grepl("\\.bam$", x, ignore.case = TRUE) ~ "BAM",
    grepl("\\.bai$", x, ignore.case = TRUE) ~ "BAMindex",
    grepl("\\.cram$", x, ignore.case = TRUE) ~ "CRAM",
    grepl("\\.crai$", x, ignore.case = TRUE) ~ "CRAMindex",
    grepl("\\.fastq.gz$", x, ignore.case = TRUE) ~ "FASTQ",
    grepl("\\.fastq$", x, ignore.case = TRUE) ~ "FASTQ",
    grepl("\\.fq$", x, ignore.case = TRUE) ~ "FASTQ",
    grepl("\\.fq\\.gz$", x, ignore.case = TRUE) ~ "FASTQ",
    grepl("manifest\\.txt$", x, ignore.case = TRUE) ~ "Manifest",
    grepl("\\.md5$", x, ignore.case = TRUE) ~ "MD5",
    grepl("md5\\.txt$", x, ignore.case = TRUE) ~ "MD5txt",
    grepl("\\.vcf$", x, ignore.case = TRUE) ~ "VCF_unz",
    grepl("\\.g\\.vcf\\.gz$", x, ignore.case = TRUE) ~ "GVCF",
    grepl("\\.vcf\\.gz$", x, ignore.case = TRUE) ~ "VCF",
    grepl("\\.tbi$", x, ignore.case = TRUE) ~ "VCFindex",
    grepl("\\.csv$", x, ignore.case = TRUE) ~ "CSV",
    grepl("\\.json$", x, ignore.case = TRUE) ~ "JSON",
    TRUE ~ "OTHER")
}

gcs_list_objects2 <- function(b, prefix) {
  googleCloudStorageR::gcs_list_objects(
    bucket = b,
    prefix = prefix,
    detail = "summary"
  ) %>%
  as_tibble() %>%
  mutate(
    name = glue("gs://{b}/{name}"),
    size = sub(" bytes", "", size), # else returns NA
    size = fs::as_fs_bytes(size),
    ftype = guess_file_type(name)
  )
}

# The given observation x is considered an outlier
# (see https://statsandr.com/blog/outliers-detection-in-r/).
# Using the m parameter for cases where there are simply too many outliers; the
# larger the value of m, the fewer values are considered outliers.
is_outlier <- function(x, m = 1.5) {
  assert_that(is.numeric(x), is.numeric(m))
  (x < quantile(x, 0.25) - m * IQR(x)) |
    (x > quantile(x, 0.75) + m * IQR(x))
}
```

```{r vars}
bucket <- glue("cpg-tob-wgs-", params$gvcf_bucket_suffix)
gcs_prefix <- "gvcf"
```

## WGS GVCF files

- Let's first explore the contents of `r glue("'{bucket}/{gcs_prefix}'")`:

```{r list_contents1}
scope <- c("https://www.googleapis.com/auth/cloud-platform")
token <- gargle::token_fetch(scopes = scope)
googleCloudStorageR::gcs_auth(token = token)
obj_list <- gcs_list_objects2(b = bucket, prefix = gcs_prefix)
```

```{r list_contents2}
count(obj_list, ftype) %>% knitr::kable(caption = glue("Count of file types in '{bucket}/{gcs_prefix}'."))
gvcf <-
  obj_list %>%
  filter(ftype == "GVCF") %>%
  mutate(basename = basename(name),
                tobid = sub(".g.vcf.gz", "", basename),
                batch = sub("batch(.)", "\\1", basename(dirname(name)))) %>%
  select(tobid, fullname = name, batch, size, basename)
```

- Total of **`r nrow(obj_list)`** files, consisting of **`r nrow(gvcf)`**
  GVCF files:

```{r gvcf_list}
gvcf %>%
  mutate(size = as.character(size),
                n = dplyr::row_number()) %>%
  select(n, fullname, batch, size) %>%
  reactable::reactable(
    pagination = FALSE, highlight = TRUE, height = 500, searchable = TRUE,
    filterable = TRUE, bordered = TRUE, fullWidth = FALSE,
    columns = list(
      n = colDef(minWidth = 60),
      fullname = colDef(minWidth = 420),
      batch = colDef(minWidth = 60),
      size = colDef(minWidth = 80)
    )
  ) %>%
  htmlwidgets::prependContent(
    htmltools::h2(
      class = "title",
      glue("GVCF files in '{bucket}/{gcs_prefix}' (Total: {nrow(gvcf)})")))
```

```{r gvcf_file_sizes}
theme_set(theme_bw())

gvcf %>%
  summarise(
    min = as_fs_bytes(min(size)),
    max = as_fs_bytes(max(size)),
    q1 = as_fs_bytes(quantile(size, 0.25)),
    median = as_fs_bytes(median(size)),
    q3 = as_fs_bytes(quantile(size, 0.75)),
    total = as_fs_bytes(sum(size)),
    .groups = "drop") %>%
  tidyr::pivot_longer(cols = dplyr::everything()) %>%
  knitr::kable(caption = glue("Size metrics for {nrow(gvcf)} GVCF files in '{bucket}/{gcs_prefix}'."))

# jitter object for proper labels
jitter_pos1 <- ggplot2::position_jitter(width = 0.10, height = 0, seed = 321)

gvcf %>%
  mutate(
    outlier = dplyr::if_else(
      is_outlier(size, 3),
      glue("{tobid} ({size})"), 
      NA_character_
    )
  ) %>%
  ggplot(aes(x = batch, y = size)) +
  geom_violin(fill="lightblue") +
  ggforce::geom_sina(shape = 21, color = "darkblue", fill = "red", seed = 42) +
  ggrepel::geom_text_repel(aes(label = outlier),
                           na.rm = TRUE, hjust = -0.6, seed = 42) +
  scale_y_continuous(labels = scales::comma, breaks = scales::breaks_pretty(10)) +
  theme(panel.grid.minor = element_blank()) +
  ggtitle(glue("Size (bytes) for {nrow(gvcf)} GVCF files in '{bucket}/{gcs_prefix}'."))
```

## QC metrics

We have access to CSV files with summaries of sample QC metrics. Additional
files have been provided containing the recorded age and sex of each sample.

```{r qc_plot_prep}
sample_qc_meta <- params$meta_tsv %>%
  read_tsv() %>%
  select(
    sample = s,
    singleton = sample_qc.n_singleton,
    snp = sample_qc.n_snp,
    ti_tv = sample_qc.r_ti_tv,
    het_hom = sample_qc.r_het_hom_var,
    indel_ratio = sample_qc.r_insertion_deletion,
    sample_filters = sample_filters,
    high_quality = high_quality,
    `chr20 mean dp` = chr20_mean_dp,
    is_female,
    sex_karyotype
  )

qc_kccg <- params$qc_csv %>%
  read_csv() %>%
  select(
    sample = sample.sample_name,
    contamination = raw_data.FREEMIX,
    chimeras = raw_data.PCT_CHIMERAS,
    duplicates = raw_data.PERCENT_DUPLICATION,
    `insert size median` = raw_data.MEDIAN_INSERT_SIZE
  )

gender <- params$gender_tsv %>%
  read_tsv(
    skip = 2,
    col_names = c(
      "sample_id",
      "sample.sample_name",
      "gender",
      paste0("nanodrop_", c("conc", "260/280", "230/280")),
      paste0("qubit_", c("assay_conc", "stock_conc")),
      "volume",
      "location"
    )
  ) %>%
  filter(!is.na(sample_id)) %>%
  select(sample = sample.sample_name, gender)

age <- params$age_csv %>%
  read_csv(col_types = cols(.default = "c", age = "d")) %>%
  select(sample = TOBIID, age)

all_data = qc_kccg %>%
  left_join(sample_qc_meta, by = "sample") %>% 
  left_join(gender, by = "sample") %>%
  left_join(age, by = "sample") %>%
  left_join(gvcf %>% select(sample = tobid, batch), by = "sample")

p_data <- qc_kccg %>%
  left_join(sample_qc_meta, by = "sample") %>%
  tidyr::pivot_longer(cols = -c("sample", "sample_filters", "high_quality", "is_female", "sex_karyotype"), names_to = "metric") %>%
  left_join(gender, by = "sample") %>%
  left_join(age, by = "sample") %>%
  left_join(gvcf %>% select(sample = tobid, batch), by = "sample") %>%
  mutate(batch = glue("batch {batch}")) %>%
  group_by(metric) %>%
  mutate(
    value2 = round(value, 3),
    label = NA_character_,
    label = if_else(is_outlier(value) & !high_quality, glue("{sample} ({value2}), {sample_filters}"), label),
    label = if_else(is_outlier(value) & high_quality,  glue("{sample} ({value2})"), label),
    label = if_else(!is_outlier(value) & !high_quality, glue("{sample}, {sample_filters}"), label)
  ) %>% 
  mutate(`Bad quality` = !high_quality)

cutoffs <- tibble(
  metric   =  c("singleton", "snp",    "het_hom", "chimeras", "chr20 mean dp", "duplicates", "contamination", "insert size median"),
  upper_lim = c(100000,       8000000,  3.3,       0.05,       NA,              0.3,          0.05,            NA),
  lower_lim = c(NA,           2400000,  NA,        NA,         15,              NA,           NA,              250)
)

cutoffs <- cutoffs %>% filter(metric %in% unique(p_data$metric))
```


Here we plot distributions of several metrics:

```{r fig.width=12, fig.height=12}
p_data %>% 
  ggplot() +
  geom_violin(aes(x = "", y = value), fill = "transparent") +
  geom_jitter(aes(x = "", y = value, colour = high_quality, shape = batch), fill = "transparent", size = 2) +
  geom_text_repel(aes(x = "", y = value, label = label), color="black", na.rm = TRUE, size = 2.3) +
  geom_hline(data = cutoffs, aes(yintercept = upper_lim), color='red') +
  geom_hline(data = cutoffs, aes(yintercept = lower_lim), color='blue') +
  facet_wrap(~metric, scales = "free", nrow = 2) +
  scale_y_continuous(breaks = scales::breaks_pretty(8)) +
  theme(axis.ticks.x = element_blank(), axis.text.x = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank()) +
  ggtitle(glue("QC metrics (for {length(unique(p_data$sample))} TOB-WGS samples).")) +
  xlab("")
```

```{r}
n_batches <- length(unique(p_data$batch))
n_metrics <- length(unique(p_data$metric))
plot_width <- n_batches * 8
plot_height <- n_metrics * 4
```

Same, grouped by batch:

```{r fig.width=plot_width, fig.height=plot_height}
p_data %>%
  #bind_rows(p_data %>% mutate(batch = "batch1"), p_data %>% mutate(batch = "batch2")) %>%  # for testing
  ggplot(aes(x = "", y = value)) +
  geom_jitter(aes(color = high_quality), fill = "transparent", size = 1) +
  geom_violin(fill = "transparent") +
  ggrepel::geom_text_repel(
    aes(x = "", y = value, label = label),
    color = "black", na.rm = TRUE, size = 2.3
  ) +
  geom_hline(data = cutoffs, aes(yintercept = upper_lim), color="red") +
  geom_hline(data = cutoffs, aes(yintercept = lower_lim), color="blue") +
  facet_grid(metric~batch, scales = "free") +
  scale_y_continuous(breaks = scales::breaks_pretty(8)) +
  theme(
    axis.ticks.x = element_blank(),
    axis.text.x = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  ) +
  ggtitle(glue("QC metrics by batch (for {length(unique(p_data$sample))} samples).")) +
  xlab("")
```

Samples with duplication rate > 0.15 in the 3rd batch:

```{r}
all_data %>% filter(batch == "2", duplicates > 0.15) %>% dplyr::pull(sample)
```

Samples with duplication rate < 0.15 in the 3rd batch:

```{r}
all_data %>% filter(batch == "2") %>% filter(duplicates < 0.15)
```

Matching inferred and reported sex. Samples that don't match:

```{r}
all_data %>% filter((sex_karyotype == "XX" & gender != "F") | (sex_karyotype == "XY" & gender != "M")) %>% 
  select(sample, sex_karyotype, reported=gender, batch, `chr20 mean dp`, contamination, sample_filters, high_quality)
```

Unique variants compared to gnomAD

```{r}

```



## Session Info

```{r session_info, echo=FALSE}
si <- sessioninfo::session_info(include_base = TRUE)
si_pl <- unclass(si$platform) %>% as_tibble() %>% t()
si_pkg <- unclass(si$packages) %>%
  as_tibble() %>%
  select(package, version = ondiskversion, datestamp = date)
tibble(var = rownames(si_pl),
              value = si_pl[, , drop = TRUE]) %>%
  knitr::kable(caption = "Platform information.")
si_pkg %>%
  DT::datatable(filter = list(position = "top", clear = FALSE, plain = TRUE),
                rownames = FALSE, extensions = c("Scroller"),
                options = list(scroller = TRUE, scrollX = TRUE, scrollY = 200,
                               dom = 'Bfrtip'))
```
